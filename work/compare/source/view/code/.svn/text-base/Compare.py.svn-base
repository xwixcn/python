# -*- coding: utf-8 -*-
import sys
import time
import os
import hashlib
import threading
from multiprocessing import Process, Manager, Pool, cpu_count
from webdataUtil import webdataUtil
#from Email import sendEmail, genAttach
from config_agent import load_config
import datetime
from gen_cookie import *
import json
from regressLogger import log
from MainCompare import *



config = load_config( "compare.cfg" )
pool_size = int( config.get( '公共配置', '进程数' ) )

class GetcompareData():
    
    def __init__( self ):
        
        self.baseurl = config.get( '多个比对', '基准环境' )
        self.testurl = config.get( '多个比对', '测试环境' )
       
    
    def __getStockCodes( self, data, tag ):
        '''
                作用:用来从指定url获取比对的股票代码
        '''
        #type {stockcode:[]}
        if tag == 1:
            if data["result"]:
                stock_codes = [stock[0] for stock in data["result"]]
            else:
                stock_codes = []
        #type [stockcode:[]]
        elif tag == 2:
            stock_codes = [i[0] for i in data["result"]]
        return stock_codes
       
    def compare( self, case ):
        '''
                作用:比较基础数据和测试数据结果
        '''
        if isinstance( case, unicode ):
                case = case.encode( 'utf-8' )
        cookie = get_abs_path( 'cookie/cookie.txt' )
        base_obj = webdataUtil( cookie )
        test_obj = webdataUtil( cookie )
        base_data = base_obj.get_ontology_data( self.baseurl, case )
        test_data = test_obj.get_ontology_data( self.testurl, case )
        base_stock_codes = self.__getStockCodes( base_data, 1 )
        test_stock_codes = self.__getStockCodes( test_data, 1 )
        time.sleep( 0.05 )
        result_dic = {}
        result_dic[case] = {"base": base_stock_codes, "test":test_stock_codes}

        case_result = {}
        value = result_dic[case]
        case_md5 = hashlib.md5( case ).hexdigest()
        try:
            if value['base'] and value['test']:
                if len( value['base'] ) != len( value['test'] ):
                    case_result = {"name":case, "bench_num":len( value['base'] ), \
                                "test_num":len( value['test'] ), "md5":case_md5 }
            elif value['base'] and not value['test']:
                case_result = {"name":case, "bench_num":len( value['base'] ), \
                            "test_num":0, "md5":case_md5, "qid":value["qid"]}
            elif value['test'] and not value['base']:
                case_result = {"name":case, "bench_num":0, \
                                   "test_num":len( value['test'] ), "md5":case_md5 }              
        except KeyError:
            case_result = {"name":case, "bench_num":0, "test_num":0, "md5":case_md5 }
        return  case_result
    


def compareresult( case ):
    return GetcompareData().compare( case )

def Multicompare( cases ):
        '''
                作用:主的比对程序
        '''
        gen_cookie()
        process_pool_2 = Pool( pool_size )
        presult = list( process_pool_2.map( compareresult, cases, len( cases ) / pool_size ) )
        process_pool_2.close()
        process_pool_2.join()
        result = {}
        resultlist = []
        for elem in presult:
            if elem:
                resultlist.append( elem )
        result["result"] = resultlist
        result["total"] = len( cases )
        result["pass"] = len( cases ) - len( resultlist )
        result["fail"] = len( resultlist )
        #result = json.dumps( result )
        return result
    
    
    
class GetOneSiteData:
    
    def __init__( self ):
        self.baseurl = config.get( '单个比对', '测试环境' )
        

    
    def get_one_site_data( self, case ):
        case = case.strip()
        onesitedata = {}
        basecookie = get_abs_path( 'cookie/cookie.txt' )
        base_obj = webdataUtil( basecookie )
        try:
            time.sleep( 0.05 )
            if isinstance( case, unicode ):
                case = case.encode( 'utf-8' )
            base_data = base_obj.get_ontology_data( self.baseurl, case )
            onesitedata["md5"] = hashlib.md5( case ).hexdigest()
            onesitedata["name"] = case
            if base_data.has_key( "result" ):
                stock_codes = [stock[0] for stock in base_data["result"]]
                num = len( stock_codes )
                if len( stock_codes ) == 0:
                    onesitedata["stocknum"] = 0
                    return onesitedata
                else:
                    return None
            else:
                onesitedata["stocknum"] = 0
                return onesitedata
        except Exception, e:
            print e
            onesitedata["unkowon"] = 1
            return onesitedata
            
          
def getonesitedata( case ):
    return GetOneSiteData().get_one_site_data( case )
    
def SingleCompare( cases ):
        '''
            获取一个网站数据
        '''
        gen_cookie()
        pool = Pool( pool_size ) 
        pool_outputs = pool.map( getonesitedata, cases, len( cases ) / pool_size ) 
        pool.close()
        pool.join()
        result = {}
        resultlist = []
        passnum = 0
        unkowonnum = 0
        failnum = 0
        for elem in list( pool_outputs ):
            if elem and not elem.has_key( "unkowon" ):
                resultlist.append( elem )
                failnum += 1
            elif elem and elem.has_key( "unkowon" ):
                unkowonnum += 1
            else:
                passnum += 1
        result["result"] = resultlist
        result["total"] = len( cases )
        result["pass"] = passnum
        result["fail"] = failnum
        result["unknown"] = unkowonnum
        #result = json.dumps( result )
        return result

def get_abs_path( file ):
     return os.path.join( os.path.dirname( __file__ ), file )




    

        
